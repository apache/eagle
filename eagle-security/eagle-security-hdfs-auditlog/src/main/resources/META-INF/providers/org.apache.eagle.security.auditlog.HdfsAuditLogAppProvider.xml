<?xml version="1.0" encoding="UTF-8" ?>
<!--
  ~ /*
  ~  *
  ~  *  * Licensed to the Apache Software Foundation (ASF) under one or more
  ~  *  * contributor license agreements.  See the NOTICE file distributed with
  ~  *  * this work for additional information regarding copyright ownership.
  ~  *  * The ASF licenses this file to You under the Apache License, Version 2.0
  ~  *  * (the "License"); you may not use this file except in compliance with
  ~  *  * the License.  You may obtain a copy of the License at
  ~  *  * <p/>
  ~  *  * http://www.apache.org/licenses/LICENSE-2.0
  ~  *  * <p/>
  ~  *  * Unless required by applicable law or agreed to in writing, software
  ~  *  * distributed under the License is distributed on an "AS IS" BASIS,
  ~  *  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~  *  * See the License for the specific language governing permissions and
  ~  *  * limitations under the License.
  ~  *
  ~  */
  -->

<application>
    <type>HDFS_AUDIT_LOG_MONITOR_APP</type>
    <name>Hdfs Audit Log Monitor</name>
    <configuration>
        <!-- topology related configurations -->
        <property>
            <name>workers</name>
            <displayName>storm workers</displayName>
            <value>1</value>
            <description>number of topology workers</description>
        </property>
        <property>
            <name>topology.numOfSpoutTasks</name>
            <displayName>Topology Spout Tasks</displayName>
            <value>2</value>
            <description>number of spout tasks</description>
        </property>
        <property>
            <name>topology.numOfParserTasks</name>
            <displayName>Topology Parser Tasks</displayName>
            <value>2</value>
            <description>number of parser tasks</description>
        </property>
        <property>
            <name>topology.numOfSensitivityJoinTasks</name>
            <displayName>Topology Sensitivity JoinTasks</displayName>
            <value>2</value>
            <description>number of sensitivity join tasks</description>
        </property>
        <property>
            <name>topology.numOfIPZoneJoinTasks</name>
            <displayName>Topology IPZone JoinTasks</displayName>
            <value>2</value>
            <description>number of ip zone join tasks</description>
        </property>
        <property>
            <name>topology.numOfSinkTasks</name>
            <displayName>Topology Sink Tasks</displayName>
            <value>2</value>
            <description>number of sink tasks</description>
        </property>
        <property>
            <name>topology.message.timeout.secs</name>
            <displayName>topology message timeout (secs)</displayName>
            <description>default timeout is 60s</description>
            <value>60</value>
        </property>

        <!-- data source configurations -->
        <property>
            <name>dataSourceConfig.topic</name>
            <displayName>Kafka Topic for Data Consumption</displayName>
            <value>hdfs_audit_log</value>
            <description>kafka topic for data consumption</description>
        </property>
        <property>
            <name>dataSourceConfig.zkConnection</name>
            <displayName>Kafka Zookeeper Connection</displayName>
            <value>localhost:2181</value>
            <description>kafka broker zk connection</description>
            <required>true</required>
        </property>
        <property>
            <name>dataSourceConfig.schemeCls</name>
            <displayName>Kafka Consumer SchemeCls</displayName>
            <value>storm.kafka.StringScheme</value>
            <description>scheme class</description>
            <required>true</required>
        </property>
        <property>
            <name>dataSourceConfig.timeZone</name>
            <displayName>Log Time Zone</displayName>
            <description>time zone of hdfs audit log </description>
            <value>GMT</value>
            <required>true</required>
        </property>

        <!-- data enrich configurations -->
        <property>
            <name>dataEnrich.dataJoinPollIntervalSec</name>
            <displayName>Data Join Poll Interval Sec</displayName>
            <value>30</value>
            <description>interval in seconds for polling</description>
        </property>

        <!-- data sink configurations -->
        <property>
            <name>dataSinkConfig.topic</name>
            <displayName>Kafka Topic for Parsed Data Sink</displayName>
            <value>hdfs_audit_log_enriched</value>
            <description>topic for kafka data sink</description>
        </property>
        <property>
            <name>dataSinkConfig.brokerList</name>
            <displayName>Kafka BrokerList for Data Sink</displayName>
            <value>localhost:6667</value>
            <description>kafka broker list</description>
            <required>true</required>
        </property>
        <property>
            <name>dataSinkConfig.serializerClass</name>
            <displayName>Kafka Producer SerializerClass</displayName>
            <value>kafka.serializer.StringEncoder</value>
            <description>serializer class Kafka message value</description>
        </property>
        <property>
            <name>dataSinkConfig.keySerializerClass</name>
            <displayName>Kafka Producer keySerializerClass</displayName>
            <value>kafka.serializer.StringEncoder</value>
            <description>serializer class Kafka message key</description>
        </property>

        <property>
            <name>dataSinkConfig.producerType</name>
            <displayName>Kafka Producer Type</displayName>
            <value>async</value>
            <description>whether the messages are sent asynchronously in a background thread</description>
        </property>
        <property>
            <name>dataSinkConfig.numBatchMessages</name>
            <displayName>Kafka Producer NumBatchMessages</displayName>
            <value>4096</value>
            <description>number of messages to send in one batch when using async mode</description>
        </property>
        <property>
            <name>dataSinkConfig.maxQueueBufferMs</name>
            <displayName>Kafka Producer MaxQueueBufferMs</displayName>
            <value>5000</value>
            <description>maximum time to buffer data when using async mode</description>
        </property>
        <property>
            <name>dataSinkConfig.requestRequiredAcks</name>
            <displayName>Kafka Producer RequestRequiredAcks</displayName>
            <value>0</value>
            <description>value controls when a produce request is considered completed</description>
        </property>
        <property>
            <name>dataSinkConfig.trafficMonitorEnabled</name>
            <displayName>Log Traffic Monitor Enabled</displayName>
            <value>false</value>
            <description>enable the log throughput calculation</description>
            <required>true</required>
        </property>
        <property>
            <name>dataSinkConfig.metricWindowSize</name>
            <displayName>Window Size for Traffic Counting</displayName>
            <value>10</value>
            <description>window size to calculate the throughput</description>
        </property>
        <property>
            <name>dataSinkConfig.metricSinkBatchSize</name>
            <displayName>Batch Size for Flushing Traffic Metrics</displayName>
            <value>1</value>
            <description>batch size of flushing metrics </description>
        </property>

        <!-- web app related configurations -->
        <property>
            <name>fs.defaultFS</name>
            <displayName>fs.defaultFS</displayName>
            <value>hdfs://localhost:8020</value>
            <description>hdfs endpoint</description>
        </property>
    </configuration>
    <streams>
        <stream>
            <streamId>hdfs_audit_log_enriched_stream</streamId>
            <description>Hdfs Audit Log Enriched Stream</description>
            <validate>true</validate>
            <timeseries>true</timeseries>
            <columns>
                <column>
                    <name>src</name>
                    <type>string</type>
                </column>
                <column>
                    <name>dst</name>
                    <type>string</type>
                </column>
                <column>
                    <name>host</name>
                    <type>string</type>
                </column>
                <column>
                    <name>timestamp</name>
                    <type>long</type>
                </column>
                <column>
                    <name>allowed</name>
                    <type>bool</type>
                </column>
                <column>
                    <name>user</name>
                    <type>string</type>
                </column>
                <column>
                    <name>cmd</name>
                    <type>string</type>
                </column>
                <column>
                    <name>sensitivityType</name>
                    <type>string</type>
                </column>
                <column>
                    <name>securityZone</name>
                    <type>string</type>
                </column>
            </columns>
        </stream>
    </streams>
    <docs>
        <install>
            <b>How to Install</b>
            <ol>
                <li>Create two kafka topics: <code>hdfs_audit_log_{SITE_ID}, hdfs_audit_log_enriched_{SITE_ID}</code></li>
                <li>Setup a log collecting tool you like to stream audit log into topic <code>hdfs_audit_log_{SITE_ID}</code></li>
                <li>Click "Install" button and edit configurations in general and advanced lists according to your requirements </li>
                <li>Check the new generated stream <code>HDFS_AUDIT_LOG_ENRICHED_STREAM_{SITE_ID}</code> at Alert -> Streams</li>
            </ol>
        </install>
        <uninstall>
            <b>How to Uninstall</b>
            <ol>
                <li>Click "Stop" button to stop the running application</li>
                <li>Remove three kafka topics</li>
                <li>Click "Uninstall" button which will remove stream <code>HDFS_AUDIT_LOG_ENRICHED_STREAM_{SITE_ID}</code></li>
            </ol>
        </uninstall>
    </docs>
</application>
