<?xml version="1.0"?>
<!-- ~ Licensed to the Apache Software Foundation (ASF) under one or more
	~ contributor license agreements. See the NOTICE file distributed with ~
	this work for additional information regarding copyright ownership. ~ The
	ASF licenses this file to You under the Apache License, Version 2.0 ~ (the
	"License"); you may not use this file except in compliance with ~ the License.
	You may obtain a copy of the License at ~ ~ http://www.apache.org/licenses/LICENSE-2.0
	~ ~ Unless required by applicable law or agreed to in writing, software ~
	distributed under the License is distributed on an "AS IS" BASIS, ~ WITHOUT
	WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. ~ See the
	License for the specific language governing permissions and ~ limitations
	under the License. -->
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

  <!-- The directories for NN, DN and SNN configs -->

  <property>
    <name>dfs.namenode.name.dir</name>
    <value>/hadoop/nn1/1</value>
    <final>true</final>
  </property>

  <property>
    <name>dfs.datanode.data.dir</name>
    <value>/hadoop/1/data,/hadoop/2/data,/hadoop/3/data,/hadoop/4/data,/hadoop/5/data,/hadoop/6/data,/hadoop/7/data,/hadoop/8/data,/hadoop/9/data,/hadoop/10/data,/hadoop/11/data,/hadoop/12/data</value>
  </property>

  <property>
    <name>dfs.blockreport.initialDelay</name>
    <value>900</value>
  </property>

  <property>
    <name>dfs.namenode.decommission.interval</name>
    <value>150</value>
  </property>

  <!-- The Nodes include and exclude -->

  <property>
    <name>dfs.hosts</name>
    <!-- The files containing hosts allowed to connect to namenode -->
    <value>/apache/hadoop/etc/hadoop/hosts</value>
  </property>

  <property>
    <name>dfs.hosts.exclude</name>
    <!-- The files containing hosts allowed to connect to namenode -->
    <value>/apache/hadoop/etc/hadoop/hdfs-exclude</value>
  </property>


  <property>
    <name>dfs.datanode.failed.volumes.tolerated</name>
    <value>3</value>
  </property>

  <property>
    <name>dfs.datanode.balance.bandwidthPerSec</name>
    <value>10485760</value>
  </property>

  <property>
    <!-- Amount of space which HDFS will refuse to use in bytes -->
    <name>dfs.datanode.du.reserved</name>
    <value>107374182400</value> <!-- 100 GB-->
  </property>

  <!-- RMERCHIA AISOPS159160 2012-09-25 -->

  <property>
    <name>dfs.heartbeat.interval</name>
    <value>6</value>
    <description>how frequently dn send a heartbeat.</description>
  </property>

  <!-- RMERCHIA AISOPS159160 2012-09-25  change to 6 hours on 2012-10-02 -->

  <property>
    <name>dfs.blockreport.intervalMsec</name>
    <value>21600000</value>
    <description>how frequently dn send a blockreport.</description>
  </property>

  <property>
    <name>dfs.namenode.safemode.threshold-pct</name>
    <value>1.0f</value>
    <!-- Allows 10 blocks unreported out of 10,000,000 -->
    <description>
      Specifies the percentage of blocks that should satisfy
      the minimal replication requirement defined by dfs.replication.min.
      Values less than or equal to 0 mean not to start in safe mode.
      Values greater than 1 will make safe mode permanent.
    </description>
  </property>

  <property>
    <name>dfs.namenode.safemode.extension</name>
    <value>120000</value>
    <!-- 2 minutes -->
    <description> Determines extension of safe mode in milliseconds after the threshold level is reached. </description>
  </property>

  <property>
    <name>dfs.permissions.enabled</name>
    <value>true</value>
    <description>
      If "true", enable permission checking in HDFS.
      If "false", permission checking is turned off,
      but all other behavior is unchanged.
      Switching from one parameter value to the other does not change the mode,
      owner or group of files or directories.
    </description>
  </property>

  <property>
    <name>dfs.replication</name>
    <value>3</value>
  </property>

  <property>
    <name>dfs.blocksize</name>
    <!-- 128mb (default 64m or 67108864) -->
    <value>268435456</value>
  </property>

  <property>
    <name>dfs.namenode.handler.count</name>
    <value>128</value>
  </property>

  <property>
    <name>dfs.datanode.handler.count</name>
    <value>50</value>
  </property>

  <!-- updated from 4k to 16k as part of HADP-6065 - miguenther - 26 august 2014 -->
  <property>
    <name>dfs.datanode.max.transfer.threads</name>
    <value>16384</value>
  </property>

  <property>
    <name>dfs.namenode.replication.max-streams</name>
    <value>40</value>
  </property>

  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.block.local-path-access.user</name>
    <value>hadoop</value>
    <description>the user who is allowed to perform short circuit reads.</description>
  </property>

  <property>
    <name>dfs.block.access.token.enable</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.namenode.name.dir.restore</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.ls.limit</name>
    <value>4096</value>
  </property>

  <!-- NameNode security config -->
  <property>
    <name>dfs.web.authentication.kerberos.keytab</name>
    <value>/etc/hadoop/hadoop.keytab</value>
  </property>
  <property>
    <name>dfs.namenode.kerberos.internal.spnego.principal</name>
    <value>*</value>
  </property>
  <property>
    <name>dfs.namenode.keytab.file</name>
    <value>/etc/hadoop/hadoop.keytab</value>
  </property>
  <property>
    <name>dfs.namenode.kerberos.principal</name>
    <value>hadoop/_HOST@APD.EBAY.COM</value>
    <!-- _HOST will be replaced by the the domain name present in fs.default.name. It is better to use the actual host name  -->
  </property>
  <property>
    <name>dfs.web.authentication.kerberos.principal</name>
    <value>HTTP/_HOST@APD.EBAY.COM,HTTP/apollo-hdfs.corp.ebay.com@CORP.EBAY.COM</value>
  </property>

  <!-- DataNode security config -->
  <property>
    <name>dfs.datanode.data.dir.perm</name>
    <value>700</value>
  </property>
  <property>
    <name>dfs.datanode.address</name>
    <value>0.0.0.0:1004</value>
  </property>
  <property>
    <name>dfs.datanode.http.address</name>
    <value>0.0.0.0:1006</value>
  </property>
  <property>
    <name>dfs.datanode.keytab.file</name>
    <value>/etc/hadoop/hadoop.keytab</value>
  </property>
  <property>
    <name>dfs.datanode.kerberos.principal</name>
    <value>hadoop/_HOST@APD.EBAY.COM</value>
    <!-- _HOST will be replaced by the frst domain name mapped to the ip -->
  </property>

  <property>
    <name>dfs.cluster.administrators</name>
    <value> hdmi-hadoopeng</value>
  </property>

  <!-- HTTPS SUPPORT -->

  <property>
    <name>dfs.https.need.client.auth</name>
    <value>false</value>
    <description>Whether SSL client certificate authentication is required
    </description>
  </property>

  <property>
    <name>dfs.https.server.keystore.resource</name>
    <value>ssl-server.xml</value>
    <description>Resource file from which ssl server keystore
      information will be extracted
    </description>
  </property>

  <property>
    <name>dfs.https.client.keystore.resource</name>
    <value>ssl-client.xml</value>
    <description>Resource file from which ssl client keystore
      information will be extracted
    </description>
  </property>

  <property>
    <name>dfs.datanode.https.address</name>
    <value>0.0.0.0:50075</value>
  </property>

  <property>
    <name>dfs.datanode.http.address</name>
    <value>0.0.0.0:1006</value>
  </property>



  <property>
    <name>dfs.domain.socket.path</name>
    <value>/var/run/hadoop-hdfs/dn</value>
  </property>

  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
  </property>


  <property>
    <name>dfs.namenode.service.handler.count</name>
    <value>55</value>
  </property>




  <!-- BEGIN properties enabled per HDP-2.1.3 upgrade -->

  <property>
    <name>dfs.namenode.acls.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.http.policy</name>
    <value>HTTP_AND_HTTPS</value>
  </property>

  <property>
    <name>dfs.web.authentication.filter</name>
    <value>org.apache.hadoop.hdfs.web.TokenAuthFilter,authentication</value>
  </property>

  <!-- END properties enabled per HDP-2.1.3 upgrade -->


  <!-- added as part of HAPD-6065 - miguenther 26 August 2014 -->
  <property>
    <name>ipc.server.read.threadpool.size</name>
    <value>3</value>
  </property>


  <!-- Apollo PHX HA Configs -->
  <property>
    <name>dfs.nameservices</name>
    <value>apollo-phx-nn-ha</value>
    <description>Logical name for this new nameservice</description>
  </property>

  <property>
    <name>dfs.ha.namenodes.apollo-phx-nn-ha</name>
    <value>nn1,nn2</value>
  </property>

  <property>
    <name>dfs.namenode.rpc-address.apollo-phx-nn-ha.nn1</name>
    <value>apollo-phx-nn.vip.ebay.com:8020</value>
  </property>

  <property>
    <name>dfs.namenode.rpc-address.apollo-phx-nn-ha.nn2</name>
    <value>apollo-phx-nn-2.vip.ebay.com:8020</value>
  </property>

  <property>
    <name>dfs.namenode.servicerpc-address.apollo-phx-nn-ha.nn1</name>
    <value>apollo-phx-nn.vip.ebay.com:8030</value>
  </property>

  <property>
    <name>dfs.namenode.servicerpc-address.apollo-phx-nn-ha.nn2</name>
    <value>apollo-phx-nn-2.vip.ebay.com:8030</value>
  </property>

  <property>
    <name>dfs.namenode.http-address.apollo-phx-nn-ha.nn1</name>
    <value>apollo-phx-nn.vip.ebay.com:50080</value>
  </property>

  <property>
    <name>dfs.namenode.http-address.apollo-phx-nn-ha.nn2</name>
    <value>apollo-phx-nn-2.vip.ebay.com:50080</value>
  </property>

  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://phxaishdc9en0010-be.phx.ebay.com:8485;phxaishdc9en0011-be.phx.ebay.com:8485;phxaishdc9en0012-be.phx.ebay.com:8485;phxaishdc9en0013-be.phx.ebay.com:8485;phxaishdc9en0014-be.phx.ebay.com:8485/apollo-phx-nn-ha</value>
  </property>

  <property>
    <name>dfs.client.failover.proxy.provider.apollo-phx-nn-ha</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>

  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence
      shell(/bin/true)
    </value>
  </property>

  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value>/home/hadoop/.ssh/id_rsa</value>
  </property>

  <property>
    <name>dfs.ha.fencing.ssh.connect-timeout</name>
    <value>30000</value>
  </property>

  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/hadoop/qjm/apollo</value>
  </property>

  <property>
    <name>dfs.journalnode.kerberos.principal</name>
    <value>hadoop/_HOST@APD.EBAY.COM</value>
  </property>

  <property>
    <name>dfs.journalnode.kerberos.internal.spnego.principal</name>
    <value>HTTP/_HOST@APD.EBAY.COM</value>
  </property>

  <property>
    <name>dfs.namenode.https-address.apollo-phx-nn-ha.nn2</name>
    <value>apollo-phx-nn-2.vip.ebay.com:50070</value>
  </property>

  <property>
    <name>dfs.namenode.https-address.apollo-phx-nn-ha.nn1</name>
    <value>apollo-phx-nn.vip.ebay.com:50070</value>
  </property>

  <property>
    <name>dfs.journalnode.keytab.file</name>
    <value>/etc/hadoop/hadoop.keytab</value>
  </property>

  <!-- Apollo HA Configs END -->

  <!-- BEGIN Selective Encryption as in Ares - Sept 01, 2015 Tiffany -->
  <property>
    <name>dfs.encrypt.data.transfer</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.encrypt.data.transfer.algorithm</name>
    <value>rc4</value>
    <final>true</final>
  </property>
  <property>
    <name>dfs.trustedchannel.resolver.class</name>
    <value>org.apache.hadoop.hdfs.datatransfer.FlagListTrustedChannelResolver</value>
    <final>true</final>
  </property>
  <property>
    <name>dfs.datatransfer.client.encrypt</name>
    <value>false</value>
    <final>true</final>
  </property>

  <!-- END Selective Encryption as in Ares - Sept 01, 2015 Tiffany -->

  <!-- Post Upgrade - improve performance - Oct 23, 2015 Tiffany -->
  <property>
    <name>dfs.client.block.write.locateFollowingBlock.retries</name>
    <value>8</value>
  </property>
  <!-- END Post Upgrade - improve performance - Oct 23, 2015 Tiffany -->

</configuration>
