<?xml version="1.0" encoding="UTF-8" ?>
<!--
  ~ Licensed to the Apache Software Foundation (ASF) under one or more
  ~ contributor license agreements.  See the NOTICE file distributed with
  ~ this work for additional information regarding copyright ownership.
  ~ The ASF licenses this file to You under the Apache License, Version 2.0
  ~ (the "License"); you may not use this file except in compliance with
  ~ the License.  You may obtain a copy of the License at
  ~
  ~    http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  -->

<application>
    <type>SPARK_HISTORY_JOB_APP</type>
    <name>Spark History Job Monitor</name>
    <version>0.5.0-incubating</version>
    <appClass>org.apache.eagle.jpm.spark.history.SparkHistoryJobApp</appClass>
    <configuration>
        <!-- topology config -->
        <property>
            <name>workers</name>
            <displayName>topology workers</displayName>
            <description>topology workers</description>
            <value>1</value>
        </property>
        <property>
            <name>topology.numOfSpoutExecutors</name>
            <displayName>spout executors</displayName>
            <description>Parallelism of sparkHistoryJobFetchSpout </description>
            <value>1</value>
        </property>
        <property>
            <name>topology.numOfSpoutTasks</name>
            <displayName>spout tasks</displayName>
            <description>Tasks Num of sparkHistoryJobFetchSpout </description>
            <value>4</value>
        </property>
        <property>
            <name>topology.numOfParseBoltExecutors</name>
            <displayName>parser bolt parallelism hint</displayName>
            <description>Parallelism of sparkHistoryJobParseBolt </description>
            <value>1</value>
        </property>
        <property>
            <name>topology.numOfParserBoltTasks</name>
            <displayName>parser bolt tasks</displayName>
            <description>Tasks Num of sparkHistoryJobParseBolt</description>
            <value>4</value>
        </property>
        <property>
            <name>topology.spoutCrawlInterval</name>
            <displayName>spout crawl interval</displayName>
            <description>Spout crawl interval (in milliseconds)</description>
            <value>10000</value>
        </property>
        <property>
            <name>topology.message.timeout.secs</name>
            <displayName>topology message timeout (secs)</displayName>
            <description>default timeout is 30s</description>
            <value>300</value>
        </property>

        <!-- datasource config -->
        <property>
            <name>dataSourceConfig.rm.url</name>
            <displayName>resource manager url</displayName>
            <description>url to fetch finished spark job list</description>
            <value>http://sandbox.hortonworks.com:8088</value>
            <required>true</required>
        </property>
        <property>
            <name>dataSourceConfig.hdfs.fs.defaultFS</name>
            <displayName>hdfs url</displayName>
            <description>target hdfs to crawl log data</description>
            <value>hdfs://sandbox.hortonworks.com:8020</value>
            <required>true</required>
        </property>
        <property>
            <name>dataSourceConfig.hdfs.baseDir</name>
            <displayName>hdfs base path for spark job data</displayName>
            <description>hdfs base path for spark job data</description>
            <value>/spark-history</value>
            <required>true</required>
        </property>

        <property>
            <name>spark.jobConf.additional.info</name>
            <displayName>additional spark job config info</displayName>
            <description>additional job config list</description>
            <value></value>
        </property>
        <property>
            <name>spark.defaultVal.spark.executor.memory</name>
            <displayName>spark.executor.memory</displayName>
            <value>1g</value>
        </property>
        <property>
            <name>spark.defaultVal.spark.driver.memory</name>
            <displayName>spark.driver.memory</displayName>
            <value>1g</value>
        </property>
        <property>
            <name>spark.defaultVal.spark.driver.cores</name>
            <displayName>spark.driver.cores</displayName>
            <value>1</value>
        </property>
        <property>
            <name>spark.defaultVal.spark.executor.cores</name>
            <displayName>spark.executor.cores</displayName>
            <value>1</value>
        </property>
        <property>
            <name>spark.defaultVal.spark.yarn.am.memory</name>
            <displayName>spark.yarn.am.memory</displayName>
            <value>512m</value>
        </property>
        <property>
            <name>spark.defaultVal.spark.yarn.am.cores</name>
            <displayName>spark.yarn.am.cores</displayName>
            <value>1</value>
        </property>
        <property>
            <name>spark.defaultVal.spark.yarn.executor.memoryOverhead.factor</name>
            <displayName>spark.yarn.executor.memoryOverhead.factor</displayName>
            <value>10</value>
        </property>
        <property>
            <name>spark.defaultVal.spark.yarn.driver.memoryOverhead.factor</name>
            <displayName>spark.yarn.driver.memoryOverhead.factor</displayName>
            <value>10</value>
        </property>
        <property>
            <name>spark.defaultVal.spark.yarn.am.memoryOverhead.factor</name>
            <displayName>spark.yarn.am.memoryOverhead.factor</displayName>
            <value>10</value>
        </property>
        <property>
            <name>spark.defaultVal.spark.yarn.overhead.min</name>
            <displayName>spark.yarn.overhead.min</displayName>
            <value>384m</value>
        </property>
    </configuration>
    <docs>
        <install>
        </install>
        <uninstall>
        </uninstall>
    </docs>
</application>