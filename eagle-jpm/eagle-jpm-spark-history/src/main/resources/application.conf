# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


{
  "siteId": "sandbox",
  "appId": "sparkHistoryJob",
  "mode": "CLUSTER",
  "workers" : 3,
  topology.message.timeout.secs: 300,

  "service":{
    host:"sandbox.hortonworks.com",
    port: 9099,
    username: "admin",
    password : "secret",
    basePath : "/rest",
    readTimeOutSeconds : 2
  },
  "zkStateConfig" : {
    "zkQuorum" : "sandbox.hortonworks.com:2181",
    "zkRoot" : "/sparkJobHistory",
    "zkSessionTimeoutMs" : 15000,
    "zkRetryTimes" : 3,
    "zkRetryInterval" : 20000,
  },

  "dataSourceConfig":{
    spark.history.server.url : "http://sandbox.hortonworks.com:18080",
    spark.history.server.username : "",
    spark.history.server.password : "",
    rm.url: "http://sandbox.hortonworks.com:8088",
    "baseDir" : "/spark-history",
    hdfs: {
      fs.defaultFS : "hdfs://sandbox.hortonworks.com:8020",
      #if not need, then do not set
      # hdfs.kerberos.principal = ,
      # hdfs.keytab.file =
      # ....
    }
  },
  "topology": {
    spoutCrawlInterval: 10000, #in ms
    numOfSpoutExecutors: 1
    numOfSpoutTasks: 4
    numOfParseBoltExecutors: 1
    numOfParserBoltTasks: 4
  },
  "spark":{
    "defaultVal": {
      spark.executor.memory:"1g",
      spark.driver.memory: "1g",
      spark.driver.cores:1,
      spark.executor.cores:1,
      spark.yarn.am.memory:"512m",
      spark.yarn.am.cores:1,
      spark.yarn.executor.memoryOverhead.factor: 10,
      spark.yarn.driver.memoryOverhead.factor: 10,
      spark.yarn.am.memoryOverhead.factor: 10,
      spark.yarn.overhead.min: "384m"
    }
  }
}