<?xml version="1.0" encoding="UTF-8" ?>
<!--
  ~ Licensed to the Apache Software Foundation (ASF) under one or more
  ~ contributor license agreements.  See the NOTICE file distributed with
  ~ this work for additional information regarding copyright ownership.
  ~ The ASF licenses this file to You under the Apache License, Version 2.0
  ~ (the "License"); you may not use this file except in compliance with
  ~ the License.  You may obtain a copy of the License at
  ~
  ~    http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  -->

<application>
    <type>SPARK_RUNNING_JOB_APP</type>
    <name>Spark Running Job Monitoring</name>
    <version>0.5.0-incubating</version>
    <appClass>org.apache.eagle.jpm.spark.running.SparkRunningJobApp</appClass>
    <configuration>
        <!-- org.apache.eagle.jpm.spark.running.SparkRunningJobAppConfig -->

        <property>
            <name>dataSourceConfig.rmUrls</name>
            <displayName>resource manager url</displayName>
            <description>url to fetch finished spark job list</description>
            <value>http://sandbox.hortonworks.com:8088</value>
            <required>true</required>
        </property>
        <property>
            <name>dataSourceConfig.hdfs.fs.defaultFS</name>
            <displayName>hdfs url</displayName>
            <description>target hdfs to crawl log data</description>
            <value>hdfs://sandbox.hortonworks.com:8020</value>
            <required>true</required>
        </property>
        <property>
            <name>dataSourceConfig.hdfs.baseDir</name>
            <displayName>hdfs base path for spark job data</displayName>
            <description>hdfs base path for spark job data</description>
            <value>/spark-history</value>
            <required>true</required>
        </property>

        <property>
            <name>workers</name>
            <displayName>topology workers</displayName>
            <description>topology workers</description>
            <value>1</value>
        </property>
        <property>
            <name>jobExtractorConfig.numOfSpoutExecutors</name>
            <displayName>spout executors</displayName>
            <description>Parallelism of sparkRunningJobFetchSpout </description>
            <value>1</value>
        </property>
        <property>
            <name>jobExtractorConfig.numOfSpoutTasks</name>
            <displayName>spout tasks</displayName>
            <description>Tasks Num of sparkRunningJobFetchSpout </description>
            <value>4</value>
        </property>
        <property>
            <name>jobExtractorConfig.numOfParseBoltExecutors</name>
            <displayName>parser bolt parallelism hint</displayName>
            <description>Parallelism of sparkRunningJobParseBolt </description>
            <value>1</value>
        </property>
        <property>
            <name>jobExtractorConfig.numOfParserBoltTasks</name>
            <displayName>parser bolt tasks</displayName>
            <description>Tasks Num of sparkRunningJobParseBolt</description>
            <value>4</value>
        </property>
        <property>
            <name>topology.message.timeout.secs</name>
            <displayName>topology message timeout (secs)</displayName>
            <description>default timeout is 30s</description>
            <value>30</value>
        </property>

        <property>
            <name>jobExtractorConfig.recoverEnabled</name>
            <displayName>recover enabled</displayName>
            <description>if recover is needed when restart</description>
            <value>false</value>
        </property>
        <property>
            <name>jobExtractorConfig.fetchRunningJobInterval</name>
            <displayName>spout fetch data interval</displayName>
            <description>spout fetch data interval (in milliseconds)</description>
            <value>15</value>
        </property>
        <property>
            <name>jobExtractorConfig.parseThreadPoolSize</name>
            <displayName>thread pool size for data parsing</displayName>
            <description>thread pool size for data parsing</description>
            <value>5</value>
        </property>
    </configuration>
    <docs>
        <install>
        </install>
        <uninstall>
        </uninstall>
    </docs>
</application>